{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上交所代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn to next page fuction \n",
    "def downlourl(currentpage):\n",
    "    url = \"http://query.sse.com.cn/commonSoaQuery.do?siteId=28&sqlId=BS_GGLL&extGGLX=&stockcode=&channelId=10743%2C10744%2C10012&extGGDL=&order=createTime%7Cdesc%2Cstockcode%7Casc&isPagination=true&pageHelp.pageSize=15&pageHelp.pageNo=\" + repr(currentpage) + \"&pageHelp.beginPage=\" + repr(currentpage) +\"&pageHelp.cacheSize=1\"\n",
    "    return(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asynchronous loadnig \n",
    "headers = {\n",
    "    'Referer':'http://www.sse.com.cn/disclosure/credibility/supervision/inquiries/',\n",
    "    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#generating target csv \n",
    "with open('sh.csv',\"w\",newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    title=['时间2','标题','公司代码','函件类别','公司简称','函件类型','时间1','网址','函件编码']\n",
    "    writer.writerow(title)\n",
    "    for page in range(1,148):\n",
    "        r = requests.get(downlourl(page), headers=headers)\n",
    "        for i in r.json()['result']:\n",
    "            result=re.search('c/(\\d+).pdf',i['docURL'])\n",
    "            writer.writerow([i['cmsOpDate'],i['docTitle'],i['stockcode'],i['extWTFL'],i['extGSJC'],i['docType'],i['createTime'],i['docURL'],re.search('c/(\\d+).pdf',i['docURL']).group(1)])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成csv (只有5个required columns)\n",
    "with open('上交所.csv',\"w\",newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    title=['公司代码','公司简称','发函日期','监管问询类型','标题']\n",
    "    writer.writerow(title)\n",
    "    for page in range(1,148):\n",
    "        r = requests.get(downlourl(page), headers=headers)\n",
    "        for i in r.json()['result']:\n",
    "            result=re.search('c/(\\d+).pdf',i['docURL'])\n",
    "            writer.writerow([i['stockcode'],i['extGSJC'],i['createTime'],i['extWTFL'],i['docTitle']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from urllib.request import quote\n",
    "import requests\n",
    "import pdfplumber\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and inspect each file \n",
    "data = pd.read_csv(\"sh2.csv\",encoding='utf-8')\n",
    "\n",
    "\n",
    "函件编码 = data.loc[:,'函件编码']\n",
    "网址 = data.loc[:,'网址']\n",
    "函件类型 = data.loc[:,'函件类型']\n",
    "\n",
    "headers = {'content-type': 'application/json',\n",
    "           'Accept-Encoding': 'gzip, deflate',\n",
    "           'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0'}\n",
    "\n",
    "baseurl = \"http://reportdocs.static.szse.cn/UpFiles/fxklwxhj/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##parse in the documenbt \n",
    "def parse(docucode):\n",
    "\n",
    "    _path = \"http://\" + quote(docucode)\n",
    "    print(_path)\n",
    "\n",
    "    resource = requests.get(_path, stream=True)\n",
    "    with open('/Users/bingcuiguo/Desktop/oa/'+re.search('c/(\\d+.pdf)', docucode).group(1),'wb') as fd:\n",
    "        for y in resource.iter_content(102400):\n",
    "            fd.write(y)\n",
    "        print(re.search('c/(\\d+.pdf)', docucode).group(1), 'Complete Download')\n",
    "    path = '/Users/bingcuiguo/Desktop/oa/'+ re.search('c/(\\d+.pdf)', docucode).group(1)\n",
    "    pdf = pdfplumber.open(path)\n",
    "    f = open(\"/Users/bingcuiguo/Desktop/oa/\" + re.search('c/(\\d+).pdf', docucode).group(1) + '.txt', 'w')\n",
    "    f2 = open(\"/Users/bingcuiguo/Desktop/oa/\" +  'anomaly_record.txt', 'a')\n",
    "    n=1\n",
    "    for page in pdf.pages:\n",
    "        n+=1\n",
    "        print(page.extract_text())\n",
    "        try:\n",
    "            f.writelines(page.extract_text())\n",
    "        except:\n",
    "            print(f'========={docucode}第{n}页解码异常==========')\n",
    "            f2.write(f'\\n ========={docucode}第{n}页解码异常==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Download pdf and save each file to txt \n",
    "for i in range(len(网址)):\n",
    "    函件名称 =re.search('c/(\\d+.pdf)', 网址[i]).group(1)\n",
    "    print(函件名称)\n",
    "    开始爬取时间 = \"这是第%d个公告\"%i\n",
    "    print(开始爬取时间)\n",
    "    print(time.strftime('%Y.%m.%d.%H:%M:%S',time.localtime(time.time())))\n",
    "    try:\n",
    "        if 函件类型[i]==\"pdf\":\n",
    "            parse(网址[i])\n",
    "            print(函件名称 + \"Success\")\n",
    "        else:\n",
    "            with open(\"/Users/bingcuiguo/Desktop/oa\"%函件名称,'wb') as f:\n",
    "                _path = baseurl + quote(函件名称) +\"?random=0.3006649122149502\"\n",
    "                request = requests.get(url=_path, headers=headers)  # 随机从user_agent列表中抽取一个元素\n",
    "                f.write(request.content)\n",
    "        结束爬取时间 = time.strftime('%Y.%m.%d.%H:%M:%S', time.localtime(time.time()))\n",
    "        print(结束爬取时间)\n",
    "        print(\"第%d个公告爬取完成\" % i)\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "        try:\n",
    "            if 函件类型[i]==\"pdf\":\n",
    "                parse(网址[i])\n",
    "                print(函件名称 + \"Success\")\n",
    "            else:\n",
    "                with open(\"/Users/bingcuiguo/Desktop/oa/%s\"%函件名称,'wb') as f:\n",
    "                    _path = baseurl + quote(函件名称) +\"?random=0.3006649122149502\"\n",
    "                    request = requests.get(url=_path, headers=headers)  # 随机从user_agent列表中抽取一个元素\n",
    "                    f.write(request.content)\n",
    "            结束爬取时间 = time.strftime('%Y.%m.%d.%H:%M:%S', time.localtime(time.time()))\n",
    "            print(结束爬取时间)\n",
    "            print(\"第%d个公告爬取完成\" % i)\n",
    "        except:\n",
    "            f2 = open(\"/Users/bingcuiguo/Desktop/oa\" + 'anomaly_record.txt', 'a')\n",
    "            f2.write(f'\\n ========={函件名称}爬取时网络异常==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put txt into a single excel file \n",
    "import os\n",
    "import docx2txt\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = []\n",
    "\n",
    "wb = Workbook()\n",
    "sheet = wb.active\n",
    "sheet['A1'].value = '公告编码'\n",
    "sheet['A2'].value = '公告内容'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readdocx(filepath):\n",
    "    content = docx2txt.process(filepath)  #打开传进来的路径\n",
    "    docucode = filepath.split('/')[-1]\n",
    "    content_list.append([docucode.split('.')[0],content])\n",
    "    content_list.append([docucode.split('.')[0],content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtxt(filepath):\n",
    "    content = open(filepath, \"r\").read()\n",
    "    docucode = filepath.split('/')[-1]\n",
    "    content_list.append([docucode.split('.')[0],content])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eachFile(filepath):\n",
    "    pathDir = os.listdir(filepath) ## return current path \n",
    "    for s in pathDir:\n",
    "        newDir=os.path.join(filepath,s)#add filename to path \n",
    "        if os.path.isfile(newDir) :     \n",
    "            doctype = os.path.splitext(newDir)[1]\n",
    "            if doctype == \".txt\":  \n",
    "                readtxt(newDir)\n",
    "            elif doctype == \".docx\":\n",
    "                readdocx(newDir)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            eachFile(newDir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"/Users/bingcuiguo/Desktop/oa/上交所\"\n",
    "eachFile(\"/Users/bingcuiguo/Desktop/oa/上交所\")\n",
    "a = 1\n",
    "for doc in content_list:\n",
    "    sheet['A%d'%a].value = doc[0]\n",
    "    sheet['B%d'%a].value = doc[1]\n",
    "    a += 1\n",
    "wb.save('上交所.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create database\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "data = pd.read_csv(\"sh.csv\")\n",
    "data = pd.DataFrame(data, columns = ['时间2','标题','公司代码','函件类别','公司简称','函件类型','时间1','网址','函件编码'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('TestDB.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "CREATE TABLE 上交所 (\n",
    "时间2,标题,公司代码,函件类别,公司简称,函件类型,时间1,网址,函件编码)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sh.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        time2 = row[0]\n",
    "        title = row[1]\n",
    "        company_code = row[2]\n",
    "        file_type = row[3]\n",
    "        company_abbr = row[4]\n",
    "        file_type2 = row[5]\n",
    "        time1 = row[6]\n",
    "        web = row[7]\n",
    "        file_code = row[8]\n",
    "        c.execute('''INSERT INTO 上交所 (时间2,标题,公司代码,函件类别,公司简称,函件类型,时间1,网址,函件编码)\n",
    "        VALUES (?,?,?,?,?,?,?,?,?)\n",
    "        ''',(time2, title, company_code, file_type, company_abbr, file_type2, time1, web, file_code))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "select 公司代码,公司简称,时间1 as 发函日期, 函件类型,标题 from 上交所;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = pd.read_excel('上交所.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "CREATE TABLE 公报内容 (\n",
    "函件编码，内容)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.to_csv('内容.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('内容.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        content_code = row[0]\n",
    "        content = row[1]\n",
    "        c.execute('''INSERT INTO 公报内容 (函件编码,内容)\n",
    "        VALUES (?,?)\n",
    "        ''',(content_code, content))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "select 公司代码,公司简称,时间1 as 发函日期, 函件类型,标题 from \n",
    "上交所 a left join (select 内容 from 公报内容) b on a.函件编码 = b.函件编码\n",
    "''')\n",
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深交所代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##通过根据切换tab_num来切换板块\n",
    "def downlourl(currentpage, tab_num):\n",
    "    url=\"http://www.szse.cn/api/report/ShowReport/data?SHOWTYPE=JSON&CATALOGID=main_wxhj&TABKEY=tab\"+ str(tab_num)+\"&PAGENO=\"+ str(currentpage)+\"&random=0.7562589043142469\"\n",
    "    return(url)\n",
    "headers = {\n",
    "    'Referer':'http://www.szse.cn/disclosure/supervision/inquire/index.html',\n",
    "    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.146 Safari/537.36'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_range = [106, 146, 144]\n",
    "with open('sz.csv',\"w\",newline='') as f:\n",
    "    title=['公司代码','公司简称','发函日期','函件类别','函件编码','公司回复','函件类型']\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(title)\n",
    "    for tab in range(1,4):\n",
    "        for page in range(1,page_range[tab-1]):\n",
    "            r = requests.get(downlourl(page, tab), headers=headers)\n",
    "            for i in r.json()[0]['data']:\n",
    "                ck=re.search(\"encode-open=(.*?)>\",i['ck'])\n",
    "                hfck=re.search(\">(.*?)<\",i['hfck'])\n",
    "                lx=(ck.group(1)).split(\".\")[1][:-1]\n",
    "                if hfck:\n",
    "                    # print(hfck.group(1))\n",
    "                    hfck=hfck.group(1)\n",
    "                try:\n",
    "                    writer.writerow([i['gsdm'],i['gsjc'],i['fhrq'],i['hjlb'],(ck.group(1))[19:-5],hfck,lx])\n",
    "                except:\n",
    "                    f2 = open(\"/Users/bingcuiguo/Desktop/oa\" + 'anomaly_record.txt', 'a')\n",
    "                    f2.write(f'\\n ========={(ck.group(1))[19:-5]}解码异常==========')\n",
    "                # writer.writerow([(ck.group(1))[19:-5],lx])\n",
    "            print('完成爬取第%d页'%page+ '第%d个tab'%tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from urllib.request import quote\n",
    "import requests\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LTTextBoxHorizontal, LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sz.csv\",encoding='utf-8')\n",
    "\n",
    "\n",
    "函件编码 = data.loc[:,'函件编码']\n",
    "函件类型 = data.loc[:,'函件类型']\n",
    "\n",
    "headers = {'content-type': 'application/json',\n",
    "           'Accept-Encoding': 'gzip, deflate',\n",
    "           'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method 'read' of '_io.BytesIO' objects>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"http://reportdocs.static.szse.cn/UpFiles/fxklwxhj/\"\n",
    "from io import BytesIO\n",
    "\n",
    "def parse(docucode):\n",
    "    # open pdf online\n",
    "    _path = baseurl + quote(docucode) +\"?random=0.3006649122149502\"\n",
    "    request = Request(url=_path, headers=headers)  # 随机从user_agent列表中抽取一个元素\n",
    "    fp = urlopen(request)\n",
    "    fp = BytesIO(fp.read())\n",
    "    # create a parser for pdf \n",
    "    parser_pdf = PDFParser(fp)\n",
    "    # create a phdf\n",
    "    doc = PDFDocument(parser_pdf)\n",
    "    parser_pdf.set_document(doc)\n",
    "    doc.set_parser(parser_pdf)\n",
    "    ##doc initialization\n",
    "    doc.initialize()\n",
    "    # detect whether it could be converted to txt \n",
    "    if not doc.is_extractable:\n",
    "        raise PDFTextExtractionNotAllowed\n",
    "    else:\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        laparams = LAParams()\n",
    "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        #for each page, get the page content and column \n",
    "        for page in doc.get_pages():\n",
    "            # use interpreter to analyze \n",
    "            interpreter.process_page(page)\n",
    "            # use aggregator to get content \n",
    "            layout = device.get_result()\n",
    "            for out in layout:\n",
    "                docname = \"/Users/bingcuiguo/Desktop/oa/深交所/\"+str(docucode).split('.')[0]+'.txt'\n",
    "                with open(docname,'a') as f:\n",
    "                    if isinstance(out, LTTextBoxHorizontal):\n",
    "                        results = out.get_text()\n",
    "                        print(results)\n",
    "                        try:\n",
    "                            f.write(results)\n",
    "                        except:\n",
    "                            \n",
    "                            print(f'========={docucode}decode anomaly==========')\n",
    "                            f3 = open(\"/Users/bingcuiguo/Desktop/oa\" + 'anomaly_record.txt', 'r')\n",
    "                            f3.write(f'\\n ========={docucode}页 decode anomaly==========')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDD00080659352.pdf\n",
      "这是第0个公告\n",
      "2021.02.04.23:44:08\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PDFDocument' object has no attribute 'set_parser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-82b29a54b199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y.%m.%d.%H:%M:%S'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m函件类型\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"pdf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m函件名称\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m函件名称\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"爬取成功\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-e7d88c44840e>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(docucode)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser_pdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mparser_pdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser_pdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m##doc initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PDFDocument' object has no attribute 'set_parser'"
     ]
    }
   ],
   "source": [
    "for i in range(len(函件编码)):\n",
    "    函件名称 = (函件编码[i] + '.' + 函件类型[i])\n",
    "    print(函件名称)\n",
    "    开始爬取时间 = \"这是第%d个公告\"%i\n",
    "    print(开始爬取时间)\n",
    "    print(time.strftime('%Y.%m.%d.%H:%M:%S',time.localtime(time.time())))\n",
    "    if 函件类型[i]==\"pdf\":\n",
    "        parse(函件名称)\n",
    "        print(函件名称 + \"爬取成功\")\n",
    "    else:\n",
    "        with open(\"/Users/bingcuiguo/Desktop/oa/深交所/%s\"%函件名称,'wb') as f:\n",
    "            _path = baseurl + quote(函件名称) +\"?random=0.3006649122149502\"\n",
    "            request = requests.get(url=_path, headers=headers)  # 随机从user_agent列表中抽取一个元素\n",
    "            f.write(request.content)\n",
    "    结束爬取时间 = time.strftime('%Y.%m.%d.%H:%M:%S', time.localtime(time.time()))\n",
    "    print(结束爬取时间)\n",
    "    print(\"第%d个公告爬取完成\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = []\n",
    "\n",
    "wb = Workbook()\n",
    "sheet = wb.active\n",
    "sheet['A1'].value = '公告编码'\n",
    "sheet['A2'].value = '公告内容'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"/Users/bingcuiguo/Desktop/oa/深交所\"\n",
    "eachFile(\"/Users/bingcuiguo/Desktop/oa/深交所\")\n",
    "a = 1\n",
    "for doc in content_list:\n",
    "    sheet['A%d'%a].value = doc[0]\n",
    "    sheet['B%d'%a].value = doc[1]\n",
    "    a += 1\n",
    "wb.save('深交所.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "data = pd.read_csv(\"sz.csv\")\n",
    "data = pd.DataFrame(data, columns = ['公司代码','公司简称','发函日期','函件类别','函件编码','公司回复','函件类型'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('TestDB.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "CREATE TABLE 深交所 (\n",
    "公司代码,公司简称,发函日期,函件类别,函件编码,公司回复,函件类型)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sz.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        company_code = row[0]\n",
    "        company_abbr = row[1]\n",
    "        time = row[2]\n",
    "        file_type = row[3]\n",
    "        file_code = row[4]\n",
    "        company_feedback = row[5]\n",
    "        file_type2 = row[6]\n",
    "        c.execute('''INSERT INTO 深交所 (公司代码,公司简称,发函日期,函件类别,函件编码,公司回复,函件类型)\n",
    "        VALUES (?,?,?,?,?,?,?)\n",
    "        ''',(compnay_code, company_abbr, time, file_type, file_code, company_feedback, file_type2))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = pd.read_excel('深交所.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "CREATE TABLE 公报内容 (\n",
    "函件编码，内容)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.to_csv('深交所内容.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('深交所内容.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        content_code = row[0]\n",
    "        content = row[1]\n",
    "        c.execute('''INSERT INTO 公报内容 (函件编码,内容)\n",
    "        VALUES (?,?)\n",
    "        ''',(content_code, content))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "select 公司代码,公司简称,时间1 as 发函日期, 函件类型 from \n",
    "深交所 a left join (select 内容 from 公报内容) b on a.函件编码 = b.函件编码\n",
    "''')\n",
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他可用方法：使用selenium模拟下载\n",
    "#### 可以提升的地方：使用multiprocessing多线程完成下载和解析可以更快的提高速度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
